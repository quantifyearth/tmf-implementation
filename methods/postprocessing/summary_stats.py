import argparse
import os
import random
import logging
from functools import partial
from multiprocessing import Pool, cpu_count, set_start_method

import numpy as np
import pandas as pd
from scipy.spatial.distance import mahalanobis  # type: ignore

REPEAT_MATCH_FINDING = 100

logging.basicConfig(level=logging.INFO, format="%(asctime)s [%(levelname)s] %(message)s")

def summary_stats(
    k: str,
    s: str,
    pairs: str
):
    k_df = pd.read_parquet(k)
    s_df = pd.read_parquet(s)
    pairs_df = pd.read_parquet(pairs)
    print("<><><><> Treatment Means <><><><>")
    print(k_df.mean())
    joined = pd.merge(pairs_df, s_df, how='left', left_on=['s_lat', "s_lng"], right_on=["lat", "lng"])
    print("<><><><> Control   Means <><><><>")
    print(joined.mean())

def main():
    # If you use the default multiprocess model then you risk deadlocks when logging (which we
    # have hit). Spawn is the default on macOS, but not on Linux.
    set_start_method("spawn")

    parser = argparse.ArgumentParser(description="Takes K and S and finds 100 sets of matches.")
    parser.add_argument(
        "--k",
        type=str,
        required=True,
        dest="k_filename",
        help="Parquet file containing pixels from K as generated by calculate_k.py"
    )
    parser.add_argument(
        "--s",
        type=str,
        required=True,
        dest="s_filename",
        help="Parquet file containing pixels from S as generated by find_potential_matches.py"
    )
    parser.add_argument(
        "--pairs",
        type=str,
        required=True,
        dest="pairs",
        help="Parquet file containing pairs as generated by find_pairs.py"
    )
    args = parser.parse_args()

    summary_stats(
        args.k_filename,
        args.s_filename,
        args.pairs
    )

if __name__ == "__main__":
    main()
